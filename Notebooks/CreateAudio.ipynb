{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Creating a lightweight preprocessing script is almost always the best approach when you want consistent, structured parsing — especially from voice-to-text.\n",
        "\n",
        "How we did define a Controlled Natural Language (CNL)\n",
        "Create a semi-natural format that's:\n",
        "\n",
        "1. Easy to dictate or speak\n",
        "\n",
        "2. Consistent enough for parsing\n",
        "\n",
        "\n",
        "GOOD Example:\n",
        "\n",
        "\"Title Operation Coastal Shield. Description Allied forces retreat. Unit U1 British Infantry Infantry 85 Friendly 3 -2.5. Feature Bunker 0 2 size 10. Event 0.01 German Armor fires U3 Fire.\"\n",
        "\n",
        "Bad Example:\n",
        "\n",
        "\"We need to pull back. The Brits are getting hit hard. The tanks are closing in. French guys are holding. There's a bunker north of them.\"\n",
        "Parsing that consistently into structured data is... tough without some help."
      ],
      "metadata": {
        "id": "pdlFDxazETpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts\n",
        "!pip install pydub\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "\n",
        "!pip install whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MASRvLNXwjEv",
        "outputId": "07dce516-d89f-4ec7-809f-ea8aedeaece9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2025.1.31)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.4\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-wliecetk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-wliecetk\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803707 sha256=348de1a58d5ecd1fa8f54d8eb0e7b37fc5540c0fa3e7471b3d6b16e2b626d3c3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rb5bgetq/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,383 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,804 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,783 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,154 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,540 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,097 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,994 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,683 kB]\n",
            "Fetched 30.1 MB in 4s (7,409 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "37 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=acd064de9159421a19b63419813bfe2950af9305d1f07a39d8cc7fc087332458\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/65/ee/4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper\n",
            "Successfully installed whisper-1.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "class Unit(BaseModel):\n",
        "    id: str\n",
        "    name: str\n",
        "    type: str  # e.g. \"infantry\", \"armor\", \"air support\"\n",
        "    strength: int  # combat effectiveness, 0–100\n",
        "    position: Optional[tuple[float, float]] = None  # (x, y) coords\n",
        "    allegiance: str  # \"friendly\" or \"enemy\"\n",
        "    status: str = \"active\"  # e.g. \"active\", \"retreating\", \"destroyed\"\n",
        "\n",
        "class TerrainFeature(BaseModel):\n",
        "    type: str  # e.g. \"hill\", \"forest\", \"building\"\n",
        "    position: tuple[float, float]\n",
        "    size: float  # area/radius in meters\n",
        "\n",
        "class Terrain(BaseModel):\n",
        "    type: str\n",
        "    features: List[TerrainFeature]\n",
        "    dimensions: Tuple[int, int]  # width x height in meters or grid\n",
        "    map_size: Optional[str] = None  # e.g., \"20x20 hexes\"\n",
        "    terrain_types: Optional[List[str]] = None  # forest, desert, urban...\n",
        "    obstacles: Optional[List[str]] = None  # walls, bunkers, etc.\n",
        "    elevation_features: Optional[List[str]] = None  # hills, ridges, etc.\n",
        "    weather: Optional[str] = None  # clear, fog, night...\n",
        "    lighting: Optional[str] = None  # daylight, artificial, etc.\n",
        "\n",
        "class Objective(BaseModel):\n",
        "    id: str\n",
        "    description: str\n",
        "    controlling_unit_ids: List[str] = []\n",
        "    completed: bool = False\n",
        "    location: Optional[tuple[float, float]]\n",
        "    priority: int = 1  # Higher number = more critical\n",
        "\n",
        "class BattleEvent(BaseModel):\n",
        "    timestamp: object  # e.g. \"00:05\", \"12:03 PM\"\n",
        "    description: str\n",
        "    involved_units: List[str] = []\n",
        "    event_type: str  # e.g. \"move\", \"fire\", \"retreat\", \"reinforce\"\n",
        "\n",
        "class Scenario(BaseModel):\n",
        "    title: str\n",
        "    description: str\n",
        "    terrain: Terrain\n",
        "    units: List[Unit]\n",
        "    objectives: List[Objective]\n",
        "    timeline: List[BattleEvent]"
      ],
      "metadata": {
        "id": "dZQmCWcEzAhV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "# Define the keyword labels we want to tokenize by\n",
        "KEYWORDS = ['Title', 'Description', 'Unit', 'Feature', 'Objective', 'Event']\n",
        "\n",
        "\n",
        "def tokenize_by_keyword(text: str):\n",
        "    text = text.replace(\"minus\", \"-\")  # Normalize voice-to-text quirks\n",
        "    pattern = r'\\b(' + '|'.join(KEYWORDS) + r')\\b(?:\\s+is)?'\n",
        "    tokens = re.split(pattern, text)\n",
        "\n",
        "    # re.split gives us a list like: ['', 'Title', ' Operation X.', 'Unit', ' ID equals ...', ...]\n",
        "    # We need to stitch it back together as {keyword: [chunks]}\n",
        "    data = defaultdict(list)\n",
        "\n",
        "    current_key = None\n",
        "    for token in tokens:\n",
        "        token = token.strip()\n",
        "        if not token:\n",
        "            continue\n",
        "        if token in KEYWORDS:\n",
        "            current_key = token\n",
        "        elif current_key:\n",
        "            data[current_key].append(token)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# Sample input\n",
        "input_text = \"\"\"Title is Operation Coastal Shield. Description is Allied Forces are retreating under fire.\n",
        "    Unit is ID equals U1. Name equals British Infantry. Type equals Infantry. Strength equals 85. Allegiance equals Friendly. X equals 3. Y equals minus 2.5.\n",
        "    Unit is ID equals U2. Name equals French Infantry. Type equals Infantry. Strength equals 80. Allegiance equals Friendly. X equals 1. Y equals minus 2.2.\n",
        "    Unit is ID equals U3. Name equals German Armor. Type equals Armor. Strength equals 92. Allegiance equals Enemy. X equals 2. Y equals minus 1.8.\n",
        "    Feature is Type equals Bunker. X equals 0. Y equals 2. Size equals 10.\n",
        "    Objective is ID equals O1. Desk equals evacuate to Boats. X equals 4. Y equals 0.5. Priority equals 1.\n",
        "    Event is Time equals 0.00. Desk equals British Infantry fallback. Units equals U1. Type equals Move.\n",
        "    Event is Time equals 0.01. Desk equals German Armor fires. Units equals U3. Type equals Fire.\n",
        "    Event is Time equals 0.01. Desk equals French Infantry Holds. Units equals U2. Type equals Hold.\"\"\"\n",
        "\n",
        "# Run the tokenizer\n",
        "tokenized_data = tokenize_by_keyword(input_text)\n",
        "\n",
        "# Pretty print the result\n",
        "pprint(dict(tokenized_data))\n",
        "for item in tokenized_data['Unit']:\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW0EuzDyFoLK",
        "outputId": "7810919c-f0cb-42d0-8d9c-f5a9780f1e72"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Description': ['Allied Forces are retreating under fire.'],\n",
            " 'Event': ['Time equals 0.00. Desk equals British Infantry fallback. Units '\n",
            "           'equals U1. Type equals Move.',\n",
            "           'Time equals 0.01. Desk equals German Armor fires. Units equals U3. '\n",
            "           'Type equals Fire.',\n",
            "           'Time equals 0.01. Desk equals French Infantry Holds. Units equals '\n",
            "           'U2. Type equals Hold.'],\n",
            " 'Feature': ['Type equals Bunker. X equals 0. Y equals 2. Size equals 10.'],\n",
            " 'Objective': ['ID equals O1. Desk equals evacuate to Boats. X equals 4. Y '\n",
            "               'equals 0.5. Priority equals 1.'],\n",
            " 'Title': ['Operation Coastal Shield.'],\n",
            " 'Unit': ['ID equals U1. Name equals British Infantry. Type equals Infantry. '\n",
            "          'Strength equals 85. Allegiance equals Friendly. X equals 3. Y '\n",
            "          'equals - 2.5.',\n",
            "          'ID equals U2. Name equals French Infantry. Type equals Infantry. '\n",
            "          'Strength equals 80. Allegiance equals Friendly. X equals 1. Y '\n",
            "          'equals - 2.2.',\n",
            "          'ID equals U3. Name equals German Armor. Type equals Armor. Strength '\n",
            "          'equals 92. Allegiance equals Enemy. X equals 2. Y equals - 1.8.']}\n",
            "ID equals U1. Name equals British Infantry. Type equals Infantry. Strength equals 85. Allegiance equals Friendly. X equals 3. Y equals - 2.5.\n",
            "ID equals U2. Name equals French Infantry. Type equals Infantry. Strength equals 80. Allegiance equals Friendly. X equals 1. Y equals - 2.2.\n",
            "ID equals U3. Name equals German Armor. Type equals Armor. Strength equals 92. Allegiance equals Enemy. X equals 2. Y equals - 1.8.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unit_id = re.compile(r\"ID\\s?\\w+\\s?(\\w+)\\.\")\n",
        "unit_name= re.compile(r\"Name\\s+\\w+\\s(.+?)\\.\")\n",
        "unit_type= re.compile(r\"Type\\s+\\w+\\s(\\w+)\\.\")\n",
        "unit_ste= re.compile(r\"Strength\\s+\\w+\\s(\\d+)\\.\")\n",
        "unit_all= re.compile(r\"Allegiance\\s+\\w+\\s(\\w+)\\.\")\n",
        "unit_x= re.compile(r\"X\\s+\\w+\\s(-?\\d+(?:\\.\\d+)?)\\.\")\n",
        "unit_y= re.compile(r\"Y\\s+\\w+\\s(-?\\d+(?:\\.\\d+)?)\\.\")\n",
        "unit_status= re.compile(r\"Status\\s+\\w+\\s(-?\\d+(?:\\.\\d+)?)\\.\")\n",
        "\n",
        "def parse_units(chunks):\n",
        "    parsed_units = []\n",
        "    for chunk in chunks:\n",
        "       # chunk = chunk.replace(\"minus\", \"-\")  # handle speech-to-text quirks if an\n",
        "        parsed_units.append(Unit(\n",
        "               id=unit_id.search(chunk).group(0),\n",
        "               name=unit_name.search(chunk).group(0),\n",
        "               type=unit_type.search(chunk)).group(0),\n",
        "               strength=int(unit_ste.search(chunk)).group(0),\n",
        "               allegiance=unit_all.search(chunk).group(0),\n",
        "               position=(float(unit_x.search(chunk).group(0)),\n",
        "                         float(unit_y.search(chunk).group(0))))\n",
        "\n",
        "    return parsed_units\n",
        "\n",
        "# Run the parser\n",
        "parse_units(tokenized_data['Unit'])\n",
        "\n",
        "uii =\"\"\"U1 British Infantry Infantry 85 Friendly 3 -2.5 active.\n",
        "U1 British Infantry Infantry 85 Friendly 3 -2.5 destroyed.\n",
        "U2 French Infantry Infantry 80 Friendly 1 -2.2 active.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "vEQs_MIgQeE6",
        "outputId": "e43b1459-76f4-404c-cd66-1a01b9e9b193"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "3 validation errors for Unit\ntype\n  Input should be a valid string [type=string_type, input_value=<re.Match object; span=(4...'Type equals Infantry.'>, input_type=Match]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nstrength\n  Field required [type=missing, input_value={'id': 'ID equals U1.', '...Type equals Infantry.'>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nallegiance\n  Field required [type=missing, input_value={'id': 'ID equals U1.', '...Type equals Infantry.'>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-d14fa2eceea5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Run the parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mparse_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m uii =\"\"\"U1 British Infantry Infantry 85 Friendly 3 -2.5 active.\n",
            "\u001b[0;32m<ipython-input-78-d14fa2eceea5>\u001b[0m in \u001b[0;36mparse_units\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m        \u001b[0;31m# chunk = chunk.replace(\"minus\", \"-\")  # handle speech-to-text quirks if an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         parsed_units.append(Unit(\n\u001b[0m\u001b[1;32m     15\u001b[0m                \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munit_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munit_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 3 validation errors for Unit\ntype\n  Input should be a valid string [type=string_type, input_value=<re.Match object; span=(4...'Type equals Infantry.'>, input_type=Match]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nstrength\n  Field required [type=missing, input_value={'id': 'ID equals U1.', '...Type equals Infantry.'>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nallegiance\n  Field required [type=missing, input_value={'id': 'ID equals U1.', '...Type equals Infantry.'>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_unit(chunk: str) -> Unit:\n",
        "  units = []\n",
        "  pattern = re.compile(\n",
        "        r\"ID equals (.*)\\. Name equals (.+?)\\. Type equals (.+?)\\. Strength equals (\\d+)\\. \"\n",
        "        r\"Allegiance equals (.+?)\\. X equals (-?\\d+\\.?\\d*)\\. Y equals (-?\\d+\\.?\\d*)\\.\")\n",
        "  match = pattern.search(chunk)\n",
        "  return Unit(\n",
        "        id=match.group(1),\n",
        "        name=match.group(2),\n",
        "        type=match.group(3),\n",
        "        strength=int(match.group(4)),\n",
        "        allegiance=match.group(5),\n",
        "        position=(float(match.group(6)), float(match.group(7)))\n",
        "    )\n",
        "\n",
        "\n",
        "def parse_feature(chunk: str) -> TerrainFeature:\n",
        "    pattern = re.compile(\n",
        "        r\"Type equals (.+?)\\. X equals (-?\\d+\\.?\\d*)\\. Y equals (-?\\d+\\.?\\d*)\\. Size equals (\\d+)\\.\"\n",
        "    )\n",
        "    match = pattern.search(chunk)\n",
        "    return TerrainFeature(\n",
        "        type=match.group(1),\n",
        "        position=(float(match.group(2)), float(match.group(3))),\n",
        "        size=float(match.group(4))\n",
        "    )\n",
        "\n",
        "\n",
        "def parse_objective(chunk: str) -> Objective:\n",
        "    pattern = re.compile(\n",
        "        r\"ID equals (\\w+)\\. Desk equals (.+?)\\. X equals (-?\\d+\\.?\\d*)\\. \"\n",
        "        r\"Y equals (-?\\d+\\.?\\d*)\\. Priority equals (\\d+)\\.\"\n",
        "    )\n",
        "    match = pattern.search(chunk)\n",
        "    return Objective(\n",
        "        id=match.group(1),\n",
        "        description=match.group(2),\n",
        "        location=(float(match.group(3)), float(match.group(4))),\n",
        "        priority=int(match.group(5))\n",
        "    )\n",
        "\n",
        "\n",
        "def parse_event(chunk: str) -> BattleEvent:\n",
        "    pattern = re.compile(\n",
        "        r\"Time equals (\\d+\\.\\d+)\\. Desk equals (.+?)\\. Units equals (\\w+)\\. Type equals (\\w+)\\.\"\n",
        "    )\n",
        "    match = pattern.search(chunk)\n",
        "    return BattleEvent(\n",
        "        timestamp=float(match.group(1)),\n",
        "        description=match.group(2),\n",
        "        involved_units=[match.group(3)],\n",
        "        event_type=match.group(4).lower()\n",
        "    )\n",
        "\n",
        "\n",
        "# -------------------- MAIN PARSER --------------------\n",
        "\n",
        "def parse_scenario(text: str) -> Scenario:\n",
        "    tokens = dict(tokenize_by_keyword(text))\n",
        "    print(tokens['Unit'])\n",
        "    title = tokens['Title'][0] if tokens['Title'] else \"Untitled Scenario\"\n",
        "    description = tokens['Description'][0] if tokens['Description'] else \"\"\n",
        "    for item in tokens['Unit']:\n",
        "      units = [parse_unit(item)]\n",
        "    features = [parse_feature(chunk) for chunk in tokens['Feature']]\n",
        "    objectives = [parse_objective(chunk) for chunk in tokens['Objective']]\n",
        "    timeline = [parse_event(chunk) for chunk in tokens['Event']]\n",
        "\n",
        "    terrain = Terrain(features=features)\n",
        "\n",
        "    return Scenario(\n",
        "        title=title,\n",
        "        description=description,\n",
        "        terrain=terrain,\n",
        "        units=units,\n",
        "        objectives=objectives,\n",
        "        timeline=timeline\n",
        "    )\n",
        "if __name__ == \"__main__\":\n",
        "    input_text = \"\"\"Title is Operation Coastal Shield. Description is Allied Forces are retreating under fire.\n",
        "    Unit is ID equals U1. Name equals British Infantry. Type equals Infantry. Strength equals 85. Allegiance equals Friendly. X equals 3. Y equals minus 2.5.\n",
        "    Unit is ID equals U2. Name equals French Infantry. Type equals Infantry. Strength equals 80. Allegiance equals Friendly. X equals 1. Y equals minus 2.2.\n",
        "    Unit is ID equals U3. Name equals German Armor. Type equals Armor. Strength equals 92. Allegiance equals Enemy. X equals 2. Y equals minus 1.8.\n",
        "    Feature is Type equals Bunker. X equals 0. Y equals 2. Size equals 10.\n",
        "    Objective is ID equals O1. Desk equals evacuate to Boats. X equals 4. Y equals 0.5. Priority equals 1.\n",
        "    Event is Time equals 0.00. Desk equals British Infantry fallback. Units equals U1. Type equals Move.\n",
        "    Event is Time equals 0.01. Desk equals German Armor fires. Units equals U3. Type equals Fire.\n",
        "    Event is Time equals 0.01. Desk equals French Infantry Holds. Units equals U2. Type equals Hold.\"\"\"\n",
        "\n",
        "    scenario = parse_scenario(input_text)\n",
        "    print(scenario.json(indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "0PvvQ15IGyt4",
        "outputId": "21a722dd-f3a8-409c-a677-46d5993ea6d6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ID equals U1. Name equals British Infantry. Type equals Infantry. Strength equals 85. Allegiance equals Friendly. X equals 3. Y equals - 2.5.', 'ID equals U2. Name equals French Infantry. Type equals Infantry. Strength equals 80. Allegiance equals Friendly. X equals 1. Y equals - 2.2.', 'ID equals U3. Name equals German Armor. Type equals Armor. Strength equals 92. Allegiance equals Enemy. X equals 2. Y equals - 1.8.']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'group'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-11c48cb46657>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m     Event is Time equals 0.01. Desk equals French Infantry Holds. Units equals U2. Type equals Hold.\"\"\"\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mscenario\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_scenario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-11c48cb46657>\u001b[0m in \u001b[0;36mparse_scenario\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparse_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparse_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Feature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mobjectives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparse_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Objective'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-11c48cb46657>\u001b[0m in \u001b[0;36mparse_unit\u001b[0;34m(chunk)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   return Unit(\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "import openai\n",
        "import os\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "scenario_text = \"\"\"Title is Operation Coastal Shield\n",
        "Description is Allied forces are retreating under fire.\n",
        "Unit is ID=U1, Name=British Infantry, Type=infantry, Strength=85, Allegiance=friendly, X=-3, Y=-2.5\n",
        "Unit is ID=U2, Name=French Infantry, Type=infantry, Strength=80, Allegiance=friendly, X=-1, Y=-2.2\n",
        "Unit is ID=U3, Name=German Armor, Type=armor, Strength=92, Allegiance=enemy, X=2, Y=-1.8\n",
        "Feature is Type=Bunker, X=0, Y=-2, Size=10\n",
        "Objective is ID=O1, Desc=Evacuate to boats, X=4, Y=0.5, Priority=1\n",
        "Event is Time=00:00, Desc=British Infantry fallback, Units=U1, Type=move\n",
        "Event is Time=00:01, Desc=German Armor fires, Units=U3, Type=fire\n",
        "Event is Time=00:01, Desc=French Infantry holds, Units=U2, Type=hold\n",
        "\"\"\"\n",
        "#TODO:add delemeinatorto end of every line\n",
        "tts = gTTS(scenario_text)\n",
        "tts.save(\"scenario.mp3\")\n",
        "AudioSegment.from_mp3(\"scenario.mp3\").export(\"scenario.wav\", format=\"wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw7xSjgKwKOB",
        "outputId": "4dca81ca-2c1a-4639-97dc-3ad90ca197e9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='scenario.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import openai\n",
        "import os\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display"
      ],
      "metadata": {
        "id": "zjpzxX4vAAsk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"scenario.wav\")\n",
        "text = result[\"text\"]\n",
        "\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfGlDnYCwhxZ",
        "outputId": "d43a8215-c58c-4254-c302-ca4b654b1027"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Title is Operation Coastal Shield. Description is Allied Forces are retreating under fire. Unit is ID equals U1. Name equals British Infantry. Type equals Infantry. Strength equals 85. Allegiance equals Friendly. X equals 3. Y equals minus 2.5. Unit is ID equals U2. Name equals French Infantry. Type equals Infantry. Strength equals 80. Allegiance equals Friendly. X equals 1. Y equals minus 2.2. Unit is ID equals U3. Name equals German Armor. Type equals Armor. Strength equals 92. Allegiance equals Enemy. X equals 2. Y equals minus 1.8. Feature is Type equals Bunker. X equals 0. Y equals 2. Size equals 10. Objective is ID equals O1. Desk equals evacuate to Boats. X equals 4. Y equals 0.5. Priority equals 1. Event is Time equals 0.00. Desk equals British Infantry fallback. Units equals U1. Type equals Move. Event is Time equals 0.01. Desk equals German Armor fires. Units equals U3. Type equals Fire. Event is Time equals 0.01. Desk equals French Infantry Holds. Units equals U2. Type equals Hold.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload(\"/content/scenario.mp3\")\n",
        "audio_path = next(iter(uploaded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "qwkFHF0QAUDN",
        "outputId": "50f6b8f1-4083-44d1-dcbd-05159559d4d4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-54cb7018-f9bf-448a-9937-fd4f5bc469fb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-54cb7018-f9bf-448a-9937-fd4f5bc469fb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d8778ea5af31>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/scenario.mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maudio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace(\"equals\", \"=\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RgMkZgl2vVz",
        "outputId": "3fccc2e2-8a54-4c21-9285-e7cc49ef33fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Title, Operation Coastal Shield, Description, Allied Forces are retreating under fire. Unit ID = U1, Name = British Infantry, Type = Infantry, Strength = 85, Allegiance = Friendly, X = 3, Y = minus 2.5, Unit, ID = U2, Name = French Infantry, Type = Infantry, Strength = 80, Allegiance = Friendly, X = 1, Y = minus 2.2, Unit, ID = U3, Name = German Armor, Type = Armor, Strength = 92, Allegiance = Enemy, X = 2, Y = minus 1.8, Feature, Type = Bunker, X = 0, Y = 2, Size = 10, Objective, ID = U1, Desk = Evacuate to Boats, X = 4, Y = 0.5, Priority = 1, Event, Time = 0, 100, Desk = British Infantry, Fullback, Units = U1, Type = Move, Event, Time = 0, 0, 1, Desk = German Armor, Fires, Units = U3, Type = Fire, Event, Time = 0, 0, 1, Desk = French Infantry Holds, Units = U2, Type = Hold,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mytext = parse_natural_scenario_text(text)"
      ],
      "metadata": {
        "id": "4AbMXdcM3xqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "eea48fc8-b2a4-404f-cf8d-05c2ed80f0e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-47104be379ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmytext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_natural_scenario_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-a0364641771d>\u001b[0m in \u001b[0;36mparse_natural_scenario_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"title\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"description\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def parse_scenario_text(text: str) -> Scenario::\n",
        "    text = text.replace(\"minus\", \"-\")  # Normalize \"minus\" to \"-\"\n",
        "\n",
        "    title = re.search(r\"Title is (.+?)\\.\", text).group(1).strip()\n",
        "    description = re.search(r\"Description is (.+?)\\.\", text).group(1).strip()\n",
        "\n",
        "    unit_pattern = re.compile(\n",
        "        r\"Unit is ID equals (\\w+)\\. Name equals (.+?)\\. Type equals (.+?)\\. Strength equals (\\d+)\\. \"\n",
        "        r\"Allegiance equals (.+?)\\. X equals (-?\\d+(?:\\.\\d+)?)\\. Y equals (-?\\d+(?:\\.\\d+)?)\\.\"\n",
        "    )\n",
        "    units = [\n",
        "        Unit(\n",
        "            id=m.group(1),\n",
        "            name=m.group(2),\n",
        "            type=m.group(3),\n",
        "            strength=int(m.group(4)),\n",
        "            allegiance=m.group(5),\n",
        "            position=Position(x=float(m.group(6)), y=float(m.group(7)))\n",
        "        )\n",
        "        for m in unit_pattern.finditer(text)\n",
        "    ]\n",
        "\n",
        "    feature_pattern = re.compile(\n",
        "        r\"Feature is Type equals (.+?)\\. X equals (-?\\d+(?:\\.\\d+)?)\\. \"\n",
        "        r\"Y equals (-?\\d+(?:\\.\\d+)?)\\. Size equals (\\d+)\\.\"\n",
        "    )\n",
        "    features = [\n",
        "        Feature(\n",
        "            type=m.group(1),\n",
        "            position=Position(x=float(m.group(2)), y=float(m.group(3))),\n",
        "            size=int(m.group(4))\n",
        "        )\n",
        "        for m in feature_pattern.finditer(text)\n",
        "    ]\n",
        "\n",
        "    objective_pattern = re.compile(\n",
        "        r\"Objective is ID equals (\\w+)\\. Desk equals (.+?)\\. X equals (-?\\d+(?:\\.\\d+)?)\\. \"\n",
        "        r\"Y equals (-?\\d+(?:\\.\\d+)?)\\. Priority equals (\\d+)\\.\"\n",
        "    )\n",
        "    objectives = [\n",
        "        Objective(\n",
        "            id=m.group(1),\n",
        "            description=m.group(2),\n",
        "            position=Position(x=float(m.group(3)), y=float(m.group(4))),\n",
        "            priority=int(m.group(5))\n",
        "        )\n",
        "        for m in objective_pattern.finditer(text)\n",
        "    ]\n",
        "\n",
        "    event_pattern = re.compile(\n",
        "        r\"Event is Time equals (\\d+\\.\\d+)\\. Desk equals (.+?)\\. Units equals (\\w+)\\. Type equals (\\w+)\\.\"\n",
        "    )\n",
        "    events = [\n",
        "        Event(\n",
        "            time=float(m.group(1)),\n",
        "            description=m.group(2),\n",
        "            units=[m.group(3)],\n",
        "            type=m.group(4)\n",
        "        )\n",
        "        for m in event_pattern.finditer(text)\n",
        "    ]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "JnmkKLS336EE",
        "outputId": "1c7267f1-446f-46b6-f7a4-b5dc37e6110a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 're' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-766f4479a136>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"minus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mparsed_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_action_render_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-766f4479a136>\u001b[0m in \u001b[0;36mparse_action_render_model\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Parse title and description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtitle_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"Title is (.+?)\\.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtitle_match\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the natural parser function\n",
        "def parse_natural_scenario_text(text: str) -> Scenario:\n",
        "    units = []\n",
        "    features = []\n",
        "    objectives = []\n",
        "    timeline = []\n",
        "    title = \"Generated Scenario\"\n",
        "    description = \"\"\n",
        "    terrain_type = \"beach\"\n",
        "    terrain_dims = (1000, 1000)\n",
        "\n",
        "    # Normalize and tokenize input\n",
        "    text = text.replace(\"equals\", \"=\")\n",
        "    text = text.replace(\"minus\", \"-\")\n",
        "    entries = [e.strip() for e in text.split(\",\") if e.strip()]\n",
        "\n",
        "    current = {}\n",
        "    section = None\n",
        "\n",
        "    def commit_unit():\n",
        "       for i in range(0,len(entries)):\n",
        "          if \"unit\" in entries[i].lower() and \"ID\" in entries[i+1]:\n",
        "            unit = Unit(\n",
        "                id=entries[i+1],\n",
        "                name=entries[i+2],\n",
        "                type=entries[i+3],\n",
        "                strength=int(entries[i+4]),\n",
        "                allegiance=entries[i+5].lower(),\n",
        "                position=(float(entries[i+6]), float(entries[i+7]))\n",
        "            )\n",
        "            units.append(unit)\n",
        "\n",
        "    def commit_feature():\n",
        "        if all(k in current for k in [\"Type\", \"X\", \"Y\", \"Size\"]):\n",
        "            features.append(TerrainFeature(\n",
        "                type=current[\"Type\"],\n",
        "                position=(float(current[\"X\"]), float(current[\"Y\"])),\n",
        "                size=float(current[\"Size\"])\n",
        "            ))\n",
        "\n",
        "    def commit_objective():\n",
        "        if all(k in current for k in [\"ID\", \"Desc\"]):\n",
        "            objectives.append(Objective(\n",
        "                id=current[\"ID\"],\n",
        "                description=current[\"Desc\"],\n",
        "                location=(float(current.get(\"X\", 0)), float(current.get(\"Y\", 0))),\n",
        "                priority=int(current.get(\"Priority\", 1))\n",
        "            ))\n",
        "\n",
        "    def commit_event():\n",
        "        if all(k in current for k in [\"Time\", \"Desc\", \"Units\", \"Type\"]):\n",
        "            timeline.append(BattleEvent(\n",
        "                timestamp=current[\"Time\"],\n",
        "                description=current[\"Desc\"],\n",
        "                involved_units=current[\"Units\"].split(\"=\"),\n",
        "                event_type=current[\"Type\"].lower()\n",
        "            ))\n",
        "\n",
        "    for entry in entries:\n",
        "        if entry.lower().startswith(\"title\"):\n",
        "            section = \"title\"\n",
        "            title = entry.split(\"=\", 1)[1].strip()\n",
        "        elif entry.lower().startswith(\"description\"):\n",
        "            section = \"description\"\n",
        "            description = entry.split(\"=\", 1)[1].strip()\n",
        "        elif entry.lower().startswith(\"unit\"):\n",
        "            if section == \"unit\": commit_unit()\n",
        "            current = {}\n",
        "            section = \"unit\"\n",
        "        elif entry.lower().startswith(\"feature\"):\n",
        "            if section == \"unit\": commit_unit()\n",
        "            if section == \"feature\": commit_feature()\n",
        "            current = {}\n",
        "            section = \"feature\"\n",
        "        elif entry.lower().startswith(\"objective\"):\n",
        "            if section == \"feature\": commit_feature()\n",
        "            if section == \"objective\": commit_objective()\n",
        "            current = {}\n",
        "            section = \"objective\"\n",
        "        elif entry.lower().startswith(\"event\"):\n",
        "            if section == \"objective\": commit_objective()\n",
        "            if section == \"event\": commit_event()\n",
        "            current = {}\n",
        "            section = \"event\"\n",
        "        else:\n",
        "            if \"=\" in entry:\n",
        "                key, value = entry.split(\"=\", 1)\n",
        "                current[key.strip().capitalize()] = value.strip()\n",
        "\n",
        "    # Final commit\n",
        "    if section == \"unit\": commit_unit()\n",
        "    if section == \"feature\": commit_feature()\n",
        "    if section == \"objective\": commit_objective()\n",
        "    if section == \"event\": commit_event()\n",
        "\n",
        "    return Scenario(\n",
        "        title=title,\n",
        "        description=description,\n",
        "        terrain=Terrain(type=terrain_type, features=features, dimensions=terrain_dims),\n",
        "        units=units,\n",
        "        objectives=objectives,\n",
        "        timeline=timeline\n",
        "    )\n"
      ],
      "metadata": {
        "id": "z_jEeSVk3tAK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace(\"equals\", \"=\")\n",
        "text = text.replace(\"minus\", \"-\")\n",
        "entries = [e.strip() for e in text.split(\",\") if e.strip()]"
      ],
      "metadata": {
        "id": "Q1UzzdiV9qIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unit, ID = U3, Name = German Armor, Type = Armor, Strength = 92, Allegiance = Enemy, X = 2, Y = minus 1.8,\n",
        "\n",
        "for i in range(0,len(entries)):\n",
        "  if \"unit\" in entries[i].lower() and \"ID\" in entries[i+1]:\n",
        "\n",
        "    print(entries[i+1],entries[i+2],entries[i+3],entries[i+4],entries[i+5],entries[i+6],entries[i+7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSbMxU0b90Ae",
        "outputId": "c7411e14-1175-4313-8308-e0486b4a51c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID = U2 Name = French Infantry Type = Infantry Strength = 80 Allegiance = Friendly X = 1 Y = - 2.2\n",
            "ID = U3 Name = German Armor Type = Armor Strength = 92 Allegiance = Enemy X = 2 Y = - 1.8\n"
          ]
        }
      ]
    }
  ]
}